{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coastal-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing, utils\n",
    "from sklearn.metrics import  make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "healthy-tolerance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.165620</td>\n",
       "      <td>0.320980</td>\n",
       "      <td>0.483299</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.273364</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.929823</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.159345</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130292</td>\n",
       "      <td>0.870736</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.436060</td>\n",
       "      <td>1.465940</td>\n",
       "      <td>0.636203</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.515587</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.068476</td>\n",
       "      <td>-0.783147</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.439463</td>\n",
       "      <td>-0.081827</td>\n",
       "      <td>-0.888236</td>\n",
       "      <td>-0.123005</td>\n",
       "      <td>0.582939</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031541</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.583590</td>\n",
       "      <td>-0.721442</td>\n",
       "      <td>-0.307984</td>\n",
       "      <td>0.710932</td>\n",
       "      <td>1.051693</td>\n",
       "      <td>0.594169</td>\n",
       "      <td>-0.533994</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229043</td>\n",
       "      <td>0.807926</td>\n",
       "      <td>-0.052442</td>\n",
       "      <td>0.082634</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.148790</td>\n",
       "      <td>0.635431</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10425</th>\n",
       "      <td>0.080916</td>\n",
       "      <td>0.588093</td>\n",
       "      <td>0.015130</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.557133</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>-0.580141</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10426</th>\n",
       "      <td>0.253730</td>\n",
       "      <td>-0.338346</td>\n",
       "      <td>0.352988</td>\n",
       "      <td>-1.154243</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>-0.557133</td>\n",
       "      <td>0.257927</td>\n",
       "      <td>0.348428</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>-0.527134</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10427</th>\n",
       "      <td>0.229043</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>0.171611</td>\n",
       "      <td>-0.002793</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.688613</td>\n",
       "      <td>0.295677</td>\n",
       "      <td>-1.088486</td>\n",
       "      <td>-0.590727</td>\n",
       "      <td>0.580142</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10428</th>\n",
       "      <td>-0.301743</td>\n",
       "      <td>0.352558</td>\n",
       "      <td>0.288973</td>\n",
       "      <td>1.638181</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.688613</td>\n",
       "      <td>0.069175</td>\n",
       "      <td>0.502761</td>\n",
       "      <td>0.625350</td>\n",
       "      <td>0.718969</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10429</th>\n",
       "      <td>-0.104241</td>\n",
       "      <td>-1.037102</td>\n",
       "      <td>0.388552</td>\n",
       "      <td>-1.099311</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>-0.307984</td>\n",
       "      <td>0.786433</td>\n",
       "      <td>-1.337547</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>-0.551063</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10430 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.266074 -0.165620  0.320980  0.483299  0.172340  0.273364  0.371178   \n",
       "1      0.130292  0.870736 -3.210528  0.062493  0.261718  1.436060  1.465940   \n",
       "2     -0.116585  0.069915  0.068476 -0.783147  0.261718  0.439463 -0.081827   \n",
       "3      0.031541  0.297600 -3.210528 -0.583590 -0.721442 -0.307984  0.710932   \n",
       "4      0.229043  0.807926 -0.052442  0.082634  0.261718  0.148790  0.635431   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10425  0.080916  0.588093  0.015130  0.002250  0.261718 -0.557133  0.371178   \n",
       "10426  0.253730 -0.338346  0.352988 -1.154243  0.172340 -0.557133  0.257927   \n",
       "10427  0.229043 -0.000745  0.171611 -0.002793  0.261718  0.688613  0.295677   \n",
       "10428 -0.301743  0.352558  0.288973  1.638181  0.261718  0.688613  0.069175   \n",
       "10429 -0.104241 -1.037102  0.388552 -1.099311  0.172340 -0.307984  0.786433   \n",
       "\n",
       "             7         8         9  10  \n",
       "0      0.929823  0.251173  0.159345  A  \n",
       "1      0.636203  0.282354  0.515587  A  \n",
       "2     -0.888236 -0.123005  0.582939  A  \n",
       "3      1.051693  0.594169 -0.533994  A  \n",
       "4      0.051062  0.032902 -0.086652  F  \n",
       "...         ...       ...       ... ..  \n",
       "10425  0.932346  0.282354 -0.580141  F  \n",
       "10426  0.348428  0.032902 -0.527134  F  \n",
       "10427 -1.088486 -0.590727  0.580142  A  \n",
       "10428  0.502761  0.625350  0.718969  E  \n",
       "10429 -1.337547  0.999528 -0.551063  X  \n",
       "\n",
       "[10430 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_av = pd.read_csv(\"avila.txt\", header=None)\n",
    "df_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "patient-cotton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "idx=  np.array(df_av.iloc[:,-1])\n",
    "y = np.zeros((len(idx)), dtype=np.int32)\n",
    "y[idx=='A'] = 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fallen-china",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#divide data into x and y\n",
    "x = df_av.iloc[:,:-1]\n",
    "\n",
    "#seeing %pos in the data\n",
    "pos = y.sum()\n",
    "neg = len(y) - pos\n",
    "\n",
    "percent_pos = round(pos/len(y)*100, 2)\n",
    "percent_neg = round(neg/len(y)*100, 2)\n",
    "\n",
    "percent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "private-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std = preprocessing.scale(x).astype(np.float32)\n",
    "y_std = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "middle-tourist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 5)\n",
      "[[0.68946593 0.68070345 0.51340206 0.65608241 0.57600419]\n",
      " [0.69005525 0.68108994 0.517974   0.65545227 0.57862526]\n",
      " [0.68445672 0.67677426 0.48839086 0.65604819 0.55896551]\n",
      " [0.69001842 0.68105095 0.51788436 0.65541231 0.57855316]\n",
      " [0.69005525 0.68109616 0.51788436 0.65548775 0.57858387]]\n"
     ]
    }
   ],
   "source": [
    "result_lr = []\n",
    "for trial in range(5):\n",
    "    #splitting into training and testing\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_std, y_std, train_size = 5000, random_state=trial,\n",
    "                                                    stratify = y_std, shuffle=True)\n",
    "\n",
    "    #encode training and testing data != continuous\n",
    "    encode_ytr = preprocessing.LabelEncoder()\n",
    "    ytr_encoded = encode_ytr.fit_transform(y_train)\n",
    "    \n",
    "    encode_yt = preprocessing.LabelEncoder()\n",
    "    yt_encoded = encode_yt.fit_transform(y_test)\n",
    "    \n",
    "    C_list = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, np.Inf]\n",
    "    alg = LogisticRegression(max_iter=5000, solver='saga')\n",
    "    param_grid =  {'penalty' : ['l1', 'l2'], 'C': C_list}\n",
    "    scoring_list = ['accuracy', 'precision', 'f1', 'roc_auc', 'recall']\n",
    "    scoring_func_dict = {'acc':accuracy_score, 'AUC':roc_auc_score,\n",
    "                        'prec':precision_score, 'recall':recall_score, 'f1':f1_score}\n",
    "    scoring_dict = {k:make_scorer(v) for k,v in scoring_func_dict.items()}\n",
    "    \n",
    "    search_result = GridSearchCV (alg, param_grid, scoring=scoring_dict, refit=False, cv=5, n_jobs=-1)\n",
    "    search_result.fit(x_train, ytr_encoded)\n",
    "    \n",
    "    res_one_trial = []\n",
    "    for k in scoring_dict.keys():\n",
    "        \n",
    "        mean_test_metric = search_result.cv_results_['mean_test_'+k]\n",
    "        best_idx = np.argmax(mean_test_metric)\n",
    "        best_params = search_result.cv_results_['params'][best_idx]\n",
    "        alg_new_5000 = LogisticRegression(max_iter=5000, solver='saga', **best_params)\n",
    "        alg_new_5000.fit(x_train, ytr_encoded)\n",
    "        \n",
    "        res_test = alg_new_5000.predict(x_test)\n",
    "        \n",
    "        res_one_model = []\n",
    "        \n",
    "        try:\n",
    "            for k_metric, func_metric in scoring_func_dict.items():\n",
    "                metric_value = func_metric(res_test, yt_encoded)\n",
    "                res_one_model.append(metric_value)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        res_one_trial.append(res_one_model)\n",
    "    \n",
    "    result_lr.append(res_one_trial)\n",
    "result_lr = np.array(result_lr)\n",
    "print(result_lr.shape)\n",
    "print(np.mean(result_lr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spoken-dallas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'AUC', 'prec', 'recall', 'f1']\n",
      "['acc', 'AUC', 'prec', 'recall', 'f1']\n"
     ]
    }
   ],
   "source": [
    "print([k for  k in scoring_dict.keys()])\n",
    "print([k for k in scoring_func_dict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-florist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
