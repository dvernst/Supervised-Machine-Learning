{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "painful-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing, utils\n",
    "from sklearn.metrics import  make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equipped-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bankrupt = pd.read_csv(\"bankrupt.csv\")\n",
    "df_bankrupt.rename(columns={ df_bankrupt.columns[-1]: \"y\" }, inplace = True)\n",
    "\n",
    "\n",
    "#divide data into x and y\n",
    "x = df_bankrupt.iloc[:,:-1]\n",
    "y = df_bankrupt.y\n",
    "\n",
    "#seeing %pos in the data\n",
    "pos = y.sum()\n",
    "neg = len(y) - pos\n",
    "\n",
    "percent_pos = round(pos/len(y)*100, 2)\n",
    "percent_neg = round(neg/len(y)*100, 2)\n",
    "\n",
    "percent_pos\n",
    "\n",
    "#since it is approximately normal, we will standardize using z dist\n",
    "x_std = preprocessing.scale(x).astype(np.float32)\n",
    "y_std = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daily-miami",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 5)\n",
      "[[0.97096    0.63421578 0.27864492 0.28333059 0.28019633]\n",
      " [0.96916    0.60896454 0.22915939 0.23384488 0.23092622]\n",
      " [0.96908    0.60978819 0.23112017 0.23545386 0.23228159]\n",
      " [0.96868    0.60779666 0.23317802 0.23143785 0.23150688]\n",
      " [0.96956    0.61502724 0.24102116 0.24572714 0.24289283]]\n"
     ]
    }
   ],
   "source": [
    "result_dt = []\n",
    "for trial in range(5):\n",
    "    #splitting into training and testing\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_std, y_std, train_size = 5000, random_state=trial,\n",
    "                                                    stratify = y_std, shuffle=True)\n",
    "\n",
    "    #encode training and testing data != continuous\n",
    "    encode_ytr = preprocessing.LabelEncoder()\n",
    "    ytr_encoded = encode_ytr.fit_transform(y_train)\n",
    "    \n",
    "    encode_yt = preprocessing.LabelEncoder()\n",
    "    yt_encoded = encode_yt.fit_transform(y_test)\n",
    "    \n",
    "    criterion_list = [\"gini\", \"entropy\"]\n",
    "    alg = DecisionTreeClassifier(splitter=\"best\")\n",
    "    param_grid = {'criterion':criterion_list}\n",
    "    scoring_list = ['accuracy', 'precision', 'f1', 'roc_auc', 'recall']\n",
    "    scoring_func_dict = {'acc':accuracy_score, 'AUC':roc_auc_score,\n",
    "                        'prec':precision_score, 'recall':recall_score, 'f1':f1_score}\n",
    "    scoring_dict = {k:make_scorer(v) for k,v in scoring_func_dict.items()}\n",
    "    \n",
    "    search_result = GridSearchCV (alg, param_grid, scoring=scoring_dict, refit=False, cv=5, n_jobs=-1)\n",
    "    search_result.fit(x_train, ytr_encoded)\n",
    "    \n",
    "    res_one_trial = []\n",
    "    for k in scoring_dict.keys():\n",
    "        \n",
    "        mean_test_metric = search_result.cv_results_['mean_test_'+k]\n",
    "        best_idx = np.argmax(mean_test_metric)\n",
    "        best_params = search_result.cv_results_['params'][best_idx]\n",
    "        alg_new_5000 = DecisionTreeClassifier(splitter=\"best\", **best_params)\n",
    "        alg_new_5000.fit(x_train, ytr_encoded)\n",
    "        \n",
    "        res_test = alg_new_5000.predict(x_test)\n",
    "        \n",
    "        res_one_model = []\n",
    "        for k_metric, func_metric in scoring_func_dict.items():\n",
    "            metric_value = func_metric(res_test, yt_encoded)\n",
    "            res_one_model.append(metric_value)\n",
    "\n",
    "        res_one_trial.append(res_one_model)\n",
    "    \n",
    "    result_dt.append(res_one_trial)\n",
    "result_dt = np.array(result_dt)\n",
    "print(result_dt.shape)\n",
    "print(np.mean(result_dt, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjusted-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'AUC', 'prec', 'recall', 'f1']\n",
      "['acc', 'AUC', 'prec', 'recall', 'f1']\n"
     ]
    }
   ],
   "source": [
    "print([k for  k in scoring_dict.keys()])\n",
    "print([k for k in scoring_func_dict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-campbell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
